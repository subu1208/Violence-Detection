{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pose=YOLO('yolov8\\yolov8x-pose-p6.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class violence:\n",
    "  def pose(self,frame):\n",
    "    b=np.zeros_like(frame)\n",
    "    res=model_pose(frame)\n",
    "    plt=res[0].plot(img=b,labels=False, boxes=False, masks=False, probs=False)\n",
    "    return plt\n",
    "  def change(self,prev,curr):\n",
    "    prev_gray = cv2.cvtColor(prev,cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros_like(prev)\n",
    "    mask[..., 1] = 255\n",
    "    gray = cv2.cvtColor(curr, cv2.COLOR_BGR2GRAY)\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray,None,0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "    return rgb\n",
    "  def fusion(self,rgb,cd):\n",
    "    img = cv2.addWeighted(rgb, 0.4, cd, 0.6, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('result/violence.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = tf.keras.applications.VGG16(include_top=True, weights='imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_layer = vgg_model.get_layer('fc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model_final = tf.keras.models.Model(inputs=vgg_model.input,\n",
    "                             outputs=transfer_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfirmata\n",
    "import time\n",
    "port = 'COM3' \n",
    "board = pyfirmata.Arduino(port)\n",
    "board.digital[11].mode=pyfirmata.PWM\n",
    "alarm_pin = board.get_pin('d:11:o')\n",
    "def trigger_alarm():\n",
    "    alarm_pin.write(1)  \n",
    "    time.sleep(2)\n",
    "    alarm_pin.write(0) \n",
    "    time.sleep(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 15259.3ms\n",
      "Speed: 30.2ms preprocess, 15259.3ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 15169.1ms\n",
      "Speed: 35.7ms preprocess, 15169.1ms inference, 2.2ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 17175.6ms\n",
      "Speed: 28.2ms preprocess, 17175.6ms inference, 0.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 17703.6ms\n",
      "Speed: 24.3ms preprocess, 17703.6ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 18599.7ms\n",
      "Speed: 38.1ms preprocess, 18599.7ms inference, 4.4ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 18374.6ms\n",
      "Speed: 22.4ms preprocess, 18374.6ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 18295.4ms\n",
      "Speed: 31.2ms preprocess, 18295.4ms inference, 4.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 17822.2ms\n",
      "Speed: 22.2ms preprocess, 17822.2ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 1 person, 8462.2ms\n",
      "Speed: 21.0ms preprocess, 8462.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7115.1ms\n",
      "Speed: 14.5ms preprocess, 7115.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 6923.9ms\n",
      "Speed: 15.2ms preprocess, 6923.9ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 1 person, 7385.9ms\n",
      "Speed: 13.0ms preprocess, 7385.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 6923.0ms\n",
      "Speed: 12.6ms preprocess, 6923.0ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 1 person, 6970.7ms\n",
      "Speed: 13.6ms preprocess, 6970.7ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 1 person, 7146.3ms\n",
      "Speed: 17.4ms preprocess, 7146.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7261.1ms\n",
      "Speed: 13.7ms preprocess, 7261.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7571.3ms\n",
      "Speed: 15.3ms preprocess, 7571.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7651.8ms\n",
      "Speed: 18.0ms preprocess, 7651.8ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7720.0ms\n",
      "Speed: 14.1ms preprocess, 7720.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7584.3ms\n",
      "Speed: 15.9ms preprocess, 7584.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7473.9ms\n",
      "Speed: 19.5ms preprocess, 7473.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7535.1ms\n",
      "Speed: 23.5ms preprocess, 7535.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 55ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7250.2ms\n",
      "Speed: 20.5ms preprocess, 7250.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7383.7ms\n",
      "Speed: 11.3ms preprocess, 7383.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7479.7ms\n",
      "Speed: 12.0ms preprocess, 7479.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7395.9ms\n",
      "Speed: 12.2ms preprocess, 7395.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7497.6ms\n",
      "Speed: 13.3ms preprocess, 7497.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 8032.5ms\n",
      "Speed: 13.5ms preprocess, 8032.5ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7412.9ms\n",
      "Speed: 17.5ms preprocess, 7412.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7341.8ms\n",
      "Speed: 23.9ms preprocess, 7341.8ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7858.1ms\n",
      "Speed: 14.2ms preprocess, 7858.1ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 8919.5ms\n",
      "Speed: 13.4ms preprocess, 8919.5ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 8265.2ms\n",
      "Speed: 15.0ms preprocess, 8265.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7615.3ms\n",
      "Speed: 13.6ms preprocess, 7615.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7437.1ms\n",
      "Speed: 12.3ms preprocess, 7437.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7266.3ms\n",
      "Speed: 13.5ms preprocess, 7266.3ms inference, 4.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7311.3ms\n",
      "Speed: 13.0ms preprocess, 7311.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7343.5ms\n",
      "Speed: 15.0ms preprocess, 7343.5ms inference, 0.6ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7377.1ms\n",
      "Speed: 15.0ms preprocess, 7377.1ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7397.3ms\n",
      "Speed: 12.5ms preprocess, 7397.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "violence\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7362.7ms\n",
      "Speed: 12.4ms preprocess, 7362.7ms inference, 4.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "violence\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture('fi87_xvid.avi')\n",
    "v=violence()\n",
    "count=1\n",
    "res1=[]\n",
    "while True:\n",
    "    print(count)\n",
    "    ret,frame=cap.read()\n",
    "    prev=np.zeros_like(frame)\n",
    "    if ret:\n",
    "        pose=v.pose(frame)\n",
    "        opt=v.change(prev,frame)\n",
    "        fus=v.fusion(pose,opt)\n",
    "        fus=fus[32:-32,68:-68]\n",
    "        fus=fus.reshape(1,224,224,3)\n",
    "        fus=vgg_model_final(fus)\n",
    "        res1.append(fus[0])\n",
    "        count+=1\n",
    "        cv2.imshow('video',frame)\n",
    "        if count>=21:\n",
    "            res1=np.array(res1)\n",
    "            res1=np.array(res1).reshape(1,20,4096)\n",
    "            res=new_model.predict(res1)\n",
    "            res1=res1[0,1:,:]\n",
    "            res1 = res1.tolist()\n",
    "            if res[0][0]>0.9906:\n",
    "                print('violence')\n",
    "                #for i in range(5):\n",
    "                #    trigger_alarm()\n",
    "            else:\n",
    "                print(\"Non-violence\")\n",
    "    else:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "    prev=frame\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 5 persons, 7054.6ms\n",
      "Speed: 15.2ms preprocess, 7054.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 5 persons, 7276.5ms\n",
      "Speed: 13.5ms preprocess, 7276.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 7591.1ms\n",
      "Speed: 15.4ms preprocess, 7591.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 7466.8ms\n",
      "Speed: 17.0ms preprocess, 7466.8ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 5 persons, 7444.0ms\n",
      "Speed: 12.2ms preprocess, 7444.0ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 7406.1ms\n",
      "Speed: 16.1ms preprocess, 7406.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7557.5ms\n",
      "Speed: 15.5ms preprocess, 7557.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 1 person, 7440.6ms\n",
      "Speed: 14.6ms preprocess, 7440.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7595.1ms\n",
      "Speed: 18.5ms preprocess, 7595.1ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7467.3ms\n",
      "Speed: 13.9ms preprocess, 7467.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 1 person, 7651.0ms\n",
      "Speed: 13.7ms preprocess, 7651.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 1 person, 7583.3ms\n",
      "Speed: 16.7ms preprocess, 7583.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7559.1ms\n",
      "Speed: 18.4ms preprocess, 7559.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7505.7ms\n",
      "Speed: 14.1ms preprocess, 7505.7ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7691.9ms\n",
      "Speed: 14.7ms preprocess, 7691.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7663.1ms\n",
      "Speed: 14.8ms preprocess, 7663.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7556.9ms\n",
      "Speed: 14.0ms preprocess, 7556.9ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7592.9ms\n",
      "Speed: 22.0ms preprocess, 7592.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7580.2ms\n",
      "Speed: 14.0ms preprocess, 7580.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 7618.4ms\n",
      "Speed: 16.4ms preprocess, 7618.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7506.2ms\n",
      "Speed: 13.5ms preprocess, 7506.2ms inference, 3.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7629.2ms\n",
      "Speed: 14.0ms preprocess, 7629.2ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7735.4ms\n",
      "Speed: 19.1ms preprocess, 7735.4ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7612.8ms\n",
      "Speed: 18.6ms preprocess, 7612.8ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7582.2ms\n",
      "Speed: 13.6ms preprocess, 7582.2ms inference, 4.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7571.9ms\n",
      "Speed: 14.5ms preprocess, 7571.9ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7540.6ms\n",
      "Speed: 14.0ms preprocess, 7540.6ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7604.6ms\n",
      "Speed: 15.0ms preprocess, 7604.6ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 7648.5ms\n",
      "Speed: 13.7ms preprocess, 7648.5ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7665.7ms\n",
      "Speed: 13.4ms preprocess, 7665.7ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 2 persons, 7740.3ms\n",
      "Speed: 13.0ms preprocess, 7740.3ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7606.7ms\n",
      "Speed: 12.4ms preprocess, 7606.7ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 3 persons, 7474.2ms\n",
      "Speed: 20.0ms preprocess, 7474.2ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 7573.5ms\n",
      "Speed: 14.7ms preprocess, 7573.5ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 56ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 8048.0ms\n",
      "Speed: 16.8ms preprocess, 8048.0ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 7673.9ms\n",
      "Speed: 14.2ms preprocess, 7673.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 7729.9ms\n",
      "Speed: 13.4ms preprocess, 7729.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 49ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 5 persons, 7474.4ms\n",
      "Speed: 13.2ms preprocess, 7474.4ms inference, 4.5ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 5 persons, 7640.9ms\n",
      "Speed: 18.9ms preprocess, 7640.9ms inference, 2.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 7733.3ms\n",
      "Speed: 14.1ms preprocess, 7733.3ms inference, 1.0ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-violence\n",
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 1024x1280 4 persons, 8201.5ms\n",
      "Speed: 17.0ms preprocess, 8201.5ms inference, 2.5ms postprocess per image at shape (1, 3, 1024, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "Non-violence\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture('no471_xvid.avi')\n",
    "v=violence()\n",
    "count=1\n",
    "res1=[]\n",
    "while True:\n",
    "    print(count)\n",
    "    ret,frame=cap.read()\n",
    "    prev=np.zeros_like(frame)\n",
    "    if ret:\n",
    "        pose=v.pose(frame)\n",
    "        opt=v.change(prev,frame)\n",
    "        fus=v.fusion(pose,opt)\n",
    "        fus=fus[32:-32,68:-68]\n",
    "        #fus=fus[128:-128,208:-208]\n",
    "        fus=fus.reshape(1,224,224,3)\n",
    "        fus=vgg_model_final(fus)\n",
    "        res1.append(fus[0])\n",
    "        count+=1\n",
    "        cv2.imshow('video',frame)\n",
    "        if count>=21:\n",
    "            res1=np.array(res1)\n",
    "            res1=np.array(res1).reshape(1,20,4096)\n",
    "            res=new_model.predict(res1)\n",
    "            res1=res1[0,1:,:]\n",
    "            res1 = res1.tolist()\n",
    "            if res[0][0]>0.9906:\n",
    "                print('violence')\n",
    "                for i in range(5):\n",
    "                    trigger_alarm()\n",
    "            else:\n",
    "                print(\"Non-violence\")\n",
    "    else:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "    prev=frame\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 960x1280 1 person, 15977.1ms\n",
      "Speed: 39.1ms preprocess, 15977.1ms inference, 0.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16299.8ms\n",
      "Speed: 21.9ms preprocess, 16299.8ms inference, 5.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16529.9ms\n",
      "Speed: 31.6ms preprocess, 16529.9ms inference, 2.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15972.5ms\n",
      "Speed: 36.5ms preprocess, 15972.5ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16221.9ms\n",
      "Speed: 25.2ms preprocess, 16221.9ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16139.9ms\n",
      "Speed: 22.2ms preprocess, 16139.9ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16165.3ms\n",
      "Speed: 19.8ms preprocess, 16165.3ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16079.3ms\n",
      "Speed: 22.4ms preprocess, 16079.3ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15670.2ms\n",
      "Speed: 22.5ms preprocess, 15670.2ms inference, 2.2ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16350.4ms\n",
      "Speed: 22.5ms preprocess, 16350.4ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16329.8ms\n",
      "Speed: 21.0ms preprocess, 16329.8ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16071.0ms\n",
      "Speed: 27.2ms preprocess, 16071.0ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16188.7ms\n",
      "Speed: 21.1ms preprocess, 16188.7ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16104.0ms\n",
      "Speed: 32.7ms preprocess, 16104.0ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15587.4ms\n",
      "Speed: 37.5ms preprocess, 15587.4ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16081.9ms\n",
      "Speed: 24.1ms preprocess, 16081.9ms inference, 4.3ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15766.2ms\n",
      "Speed: 25.4ms preprocess, 15766.2ms inference, 1.3ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 12371.6ms\n",
      "Speed: 22.5ms preprocess, 12371.6ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15394.9ms\n",
      "Speed: 20.9ms preprocess, 15394.9ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4096)\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16104.9ms\n",
      "Speed: 20.6ms preprocess, 16104.9ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 168ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99001   0.0099854]]\n",
      "Non-violence\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15661.5ms\n",
      "Speed: 26.2ms preprocess, 15661.5ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 109ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99051   0.0094865]]\n",
      "Non-violence\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16075.4ms\n",
      "Speed: 25.1ms preprocess, 16075.4ms inference, 2.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "[[    0.99054   0.0094606]]\n",
      "Non-violence\n",
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 960x1280 1 person, 15984.6ms\n",
      "Speed: 22.9ms preprocess, 15984.6ms inference, 2.5ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "[[     0.9908   0.0091961]]\n",
      "violence\n",
      "[[     0.9908   0.0091961]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15458.9ms\n",
      "Speed: 35.6ms preprocess, 15458.9ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "[[    0.99072   0.0092844]]\n",
      "violence\n",
      "[[    0.99072   0.0092844]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16229.3ms\n",
      "Speed: 34.8ms preprocess, 16229.3ms inference, 3.9ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "[[    0.99098   0.0090195]]\n",
      "violence\n",
      "[[    0.99098   0.0090195]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15970.7ms\n",
      "Speed: 37.6ms preprocess, 15970.7ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "[[    0.99101   0.0089946]]\n",
      "violence\n",
      "[[    0.99101   0.0089946]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15938.8ms\n",
      "Speed: 36.4ms preprocess, 15938.8ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 98ms/step\n",
      "[[      0.991   0.0090012]]\n",
      "violence\n",
      "[[      0.991   0.0090012]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16065.5ms\n",
      "Speed: 28.2ms preprocess, 16065.5ms inference, 2.4ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 96ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0.9907   0.0093038]]\n",
      "Non-violence\n",
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15679.5ms\n",
      "Speed: 23.8ms preprocess, 15679.5ms inference, 3.4ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "[[    0.99079   0.0092136]]\n",
      "violence\n",
      "[[    0.99079   0.0092136]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15991.7ms\n",
      "Speed: 36.0ms preprocess, 15991.7ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "[[    0.99091   0.0090888]]\n",
      "violence\n",
      "[[    0.99091   0.0090888]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 (no detections), 16188.0ms\n",
      "Speed: 41.3ms preprocess, 16188.0ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0.9906   0.0093993]]\n",
      "Non-violence\n",
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 (no detections), 16743.6ms\n",
      "Speed: 22.9ms preprocess, 16743.6ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99059   0.0094129]]\n",
      "Non-violence\n",
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 (no detections), 15386.8ms\n",
      "Speed: 26.3ms preprocess, 15386.8ms inference, 3.5ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 96ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0.9905   0.0094989]]\n",
      "Non-violence\n",
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15992.1ms\n",
      "Speed: 18.7ms preprocess, 15992.1ms inference, 2.3ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 87ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99046   0.0095395]]\n",
      "Non-violence\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15708.3ms\n",
      "Speed: 26.7ms preprocess, 15708.3ms inference, 2.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "[[    0.99057   0.0094284]]\n",
      "Non-violence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16260.5ms\n",
      "Speed: 21.7ms preprocess, 16260.5ms inference, 2.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "[[    0.99079   0.0092148]]\n",
      "violence\n",
      "[[    0.99079   0.0092148]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15757.6ms\n",
      "Speed: 35.2ms preprocess, 15757.6ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "[[    0.99093   0.0090692]]\n",
      "violence\n",
      "[[    0.99093   0.0090692]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16103.4ms\n",
      "Speed: 41.6ms preprocess, 16103.4ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 107ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0.9906   0.0093966]]\n",
      "Non-violence\n",
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15105.0ms\n",
      "Speed: 20.9ms preprocess, 15105.0ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "[[    0.99097   0.0090311]]\n",
      "violence\n",
      "[[    0.99097   0.0090311]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16415.0ms\n",
      "Speed: 35.3ms preprocess, 16415.0ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "[[    0.99087   0.0091259]]\n",
      "violence\n",
      "[[    0.99087   0.0091259]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 (no detections), 16145.0ms\n",
      "Speed: 45.2ms preprocess, 16145.0ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 96ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99054   0.0094643]]\n",
      "Non-violence\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 (no detections), 16040.6ms\n",
      "Speed: 20.3ms preprocess, 16040.6ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 85ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99051   0.0094852]]\n",
      "Non-violence\n",
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 (no detections), 15551.6ms\n",
      "Speed: 20.8ms preprocess, 15551.6ms inference, 2.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99059   0.0094077]]\n",
      "Non-violence\n",
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15941.7ms\n",
      "Speed: 16.3ms preprocess, 15941.7ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "[[    0.99084   0.0091644]]\n",
      "violence\n",
      "[[    0.99084   0.0091644]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16066.3ms\n",
      "Speed: 42.5ms preprocess, 16066.3ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "[[    0.99093   0.0090681]]\n",
      "violence\n",
      "[[    0.99093   0.0090681]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15855.0ms\n",
      "Speed: 35.5ms preprocess, 15855.0ms inference, 4.6ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 102ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99053   0.0094652]]\n",
      "Non-violence\n",
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15564.3ms\n",
      "Speed: 17.4ms preprocess, 15564.3ms inference, 3.5ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "[[    0.99057   0.0094268]]\n",
      "Non-violence\n",
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 960x1280 1 person, 15880.0ms\n",
      "Speed: 21.7ms preprocess, 15880.0ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 95ms/step\n",
      "[[    0.99029   0.0097052]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-violence\n",
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15848.1ms\n",
      "Speed: 25.1ms preprocess, 15848.1ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "[[    0.99055   0.0094503]]\n",
      "Non-violence\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 960x1280 1 person, 15812.4ms\n",
      "Speed: 34.7ms preprocess, 15812.4ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 100ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99051   0.0094875]]\n",
      "Non-violence\n",
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 16042.5ms\n",
      "Speed: 27.8ms preprocess, 16042.5ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 97ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99052   0.0094751]]\n",
      "Non-violence\n",
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15811.9ms\n",
      "Speed: 23.3ms preprocess, 15811.9ms inference, 2.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 91ms/step\n",
      "[[    0.99069   0.0093137]]\n",
      "Non-violence\n",
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 960x1280 2 persons, 15710.9ms\n",
      "Speed: 26.5ms preprocess, 15710.9ms inference, 5.1ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "[[    0.99075   0.0092539]]\n",
      "violence\n",
      "[[    0.99075   0.0092539]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 2 persons, 15145.0ms\n",
      "Speed: 24.4ms preprocess, 15145.0ms inference, 3.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "[[    0.99096   0.0090401]]\n",
      "violence\n",
      "[[    0.99096   0.0090401]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15700.5ms\n",
      "Speed: 45.8ms preprocess, 15700.5ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 102ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99041   0.0095868]]\n",
      "Non-violence\n",
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 15687.8ms\n",
      "Speed: 20.8ms preprocess, 15687.8ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "[[    0.99047   0.0095298]]\n",
      "Non-violence\n",
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 960x1280 (no detections), 12982.7ms\n",
      "Speed: 20.4ms preprocess, 12982.7ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 91ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0.99061   0.0093873]]\n",
      "Non-violence\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 960x1280 1 person, 13747.0ms\n",
      "Speed: 19.7ms preprocess, 13747.0ms inference, 4.0ms postprocess per image at shape (1, 3, 960, 1280)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 4096)\n",
      "(20, 4096)\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "[[    0.99092   0.0090838]]\n",
      "violence\n",
      "[[    0.99092   0.0090838]]\n"
     ]
    },
    {
     "ename": "SerialException",
     "evalue": "WriteFile failed (PermissionError(13, 'The device does not recognize the command.', None, 22))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSerialException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res)\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m---> 33\u001b[0m          \u001b[43mtrigger_alarm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-violence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m, in \u001b[0;36mtrigger_alarm\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrigger_alarm\u001b[39m():\n\u001b[1;32m----> 8\u001b[0m     \u001b[43malarm_pin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      9\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     10\u001b[0m     alarm_pin\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;241m0\u001b[39m) \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyfirmata\\pyfirmata.py:545\u001b[0m, in \u001b[0;36mPin.write\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    543\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(value \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m))\n\u001b[0;32m    544\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m([ANALOG_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpin_number, value \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m128\u001b[39m, value \u001b[38;5;241m>>\u001b[39m \u001b[38;5;241m7\u001b[39m])\n\u001b[1;32m--> 545\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01mis\u001b[39;00m SERVO:\n\u001b[0;32m    547\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(value)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\serial\\serialwin32.py:317\u001b[0m, in \u001b[0;36mSerial.write\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_timeout \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# if blocking (None) or w/ write timeout (>0)\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success \u001b[38;5;129;01mand\u001b[39;00m win32\u001b[38;5;241m.\u001b[39mGetLastError() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (win32\u001b[38;5;241m.\u001b[39mERROR_SUCCESS, win32\u001b[38;5;241m.\u001b[39mERROR_IO_PENDING):\n\u001b[1;32m--> 317\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SerialException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWriteFile failed (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ctypes\u001b[38;5;241m.\u001b[39mWinError()))\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# Wait for the write to complete.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;66;03m#~ win32.WaitForSingleObject(self._overlapped_write.hEvent, win32.INFINITE)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     win32\u001b[38;5;241m.\u001b[39mGetOverlappedResult(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_port_handle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overlapped_write, ctypes\u001b[38;5;241m.\u001b[39mbyref(n), \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mSerialException\u001b[0m: WriteFile failed (PermissionError(13, 'The device does not recognize the command.', None, 22))"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "v=violence()\n",
    "count=1\n",
    "res1=[]\n",
    "while True:\n",
    "    print(count)\n",
    "    ret,frame=cap.read()\n",
    "    prev=np.zeros_like(frame)\n",
    "    if ret:\n",
    "        pose=v.pose(frame)\n",
    "        opt=v.change(prev,frame)\n",
    "        fus=v.fusion(pose,opt)\n",
    "        fus=fus[128:-128,208:-208]\n",
    "        print(fus.shape)\n",
    "        fus=fus.reshape(1,224,224,3)\n",
    "        fus=vgg_model_final(fus)\n",
    "        print(fus.shape)\n",
    "        res1.append(fus[0])\n",
    "        count+=1\n",
    "        cv2.imshow('video',frame)\n",
    "        if count>=21:\n",
    "            res1=np.array(res1)\n",
    "            print(res1.shape)\n",
    "            res1=np.array(res1).reshape(1,20,4096)\n",
    "            res=new_model.predict(res1)\n",
    "            res1=res1[0,1:,:]\n",
    "            res1 = res1.tolist()\n",
    "            print(res)\n",
    "            if res[0][0]>0.9907:\n",
    "                print('violence')\n",
    "                print(res)\n",
    "                for i in range(5):\n",
    "                     trigger_alarm()\n",
    "            else:\n",
    "                print(\"Non-violence\")\n",
    "    else:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "    prev=frame\n",
    "cap.release() \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
